{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPARSE] Backend: spconv, Attention: flash_attn\n",
      "Warp 1.5.0 initialized:\n",
      "   CUDA Toolkit 12.6, Driver 12.2\n",
      "   Devices:\n",
      "     \"cpu\"      : \"x86_64\"\n",
      "     \"cuda:0\"   : \"NVIDIA GeForce RTX 3090\" (24 GiB, sm_86, mempool enabled)\n",
      "   Kernel cache:\n",
      "     /home/ehliang/.cache/warp/1.5.0\n",
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ['ATTN_BACKEND'] = 'xformers'   # Can be 'flash-attn' or 'xformers', default is 'flash-attn'\n",
    "os.environ['SPCONV_ALGO'] = 'native'        # Can be 'native' or 'auto', default is 'auto'.\n",
    "                                            # 'auto' is faster but will do benchmarking at the beginning.\n",
    "                                            # Recommended to set to 'native' if run only once.\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "import imageio\n",
    "from PIL import Image\n",
    "from mesh_extraction.trellis.pipelines import TrellisImageTo3DPipeline\n",
    "from mesh_extraction.trellis.utils import render_utils, postprocessing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPARSE][CONV] spconv algo: native\n",
      "[ATTENTION] Using backend: flash_attn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ehliang/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/home/ehliang/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/home/ehliang/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/home/ehliang/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n"
     ]
    }
   ],
   "source": [
    "def get_pipeline():\n",
    "    pipeline = TrellisImageTo3DPipeline.from_pretrained(\"JeffreyXiang/TRELLIS-image-large\")\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "pipeline = get_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(source_path, output_path, pipeline, pointcloud_path):\n",
    "\n",
    "    pipeline.cuda()\n",
    "\n",
    "    images = []\n",
    "\n",
    "    frame_names = [\n",
    "        p for p in os.listdir(source_path)\n",
    "    ]\n",
    "    frame_names.sort(key=lambda p: int(os.path.splitext(p)[0].split(\"_\")[1]))\n",
    "\n",
    "    # Load an image\n",
    "    for i, image_name in enumerate(frame_names):\n",
    "        if i % 1 == 0:\n",
    "            print(image_name)\n",
    "            images.append(Image.open(os.path.join(source_path, image_name)))\n",
    "\n",
    "\n",
    "    # Run the pipeline\n",
    "    output = pipeline.run(\n",
    "        images,\n",
    "        # Optional parameters\n",
    "        seed=1,\n",
    "        main_path=pointcloud_path,\n",
    "        # sparse_structure_sampler_params={\n",
    "        #     \"steps\": 12,\n",
    "        #     \"cfg_strength\": 7.5,\n",
    "        # },\n",
    "        # slat_sampler_params={\n",
    "        #     \"steps\": 12,\n",
    "        #     \"cfg_strength\": 3,\n",
    "        # },\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Render the outputs\n",
    "    video = render_utils.render_video(output['gaussian'][0])['color']\n",
    "    imageio.mimsave(\"sample_gs.mp4\", video, fps=30)\n",
    "    video = render_utils.render_video(output['mesh'][0])['normal']\n",
    "    imageio.mimsave(\"sample_mesh.mp4\", video, fps=30)\n",
    "    # GLB files can be extracted from the output\n",
    "    glb = postprocessing_utils.to_glb(\n",
    "        output['gaussian'][0],\n",
    "        output['mesh'][0],\n",
    "        # Optional parameters\n",
    "        simplify=0.1,          # Ratio of triangles to remove in the simplification process\n",
    "        texture_size=1024,      # Size of the texture used for the GLB\n",
    "    )\n",
    "    glb.export(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rgb_0.png\n",
      "rgb_1.png\n",
      "rgb_2.png\n",
      "rgb_3.png\n",
      "rgb_4.png\n",
      "rgb_5.png\n",
      "rgb_6.png\n",
      "rgb_7.png\n",
      "rgb_8.png\n",
      "rgb_9.png\n",
      "rgb_10.png\n",
      "rgb_11.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 25/25 [00:05<00:00,  4.34it/s]\n",
      "Sampling: 100%|██████████| 25/25 [00:05<00:00,  4.57it/s]\n",
      "Sampling: 100%|██████████| 25/25 [00:05<00:00,  4.47it/s]\n",
      "Sampling: 100%|██████████| 25/25 [00:05<00:00,  4.48it/s]\n",
      "Sampling: 100%|██████████| 25/25 [00:05<00:00,  4.45it/s]\n",
      "Sampling: 100%|██████████| 25/25 [00:05<00:00,  4.54it/s]\n",
      "Sampling: 100%|██████████| 25/25 [00:05<00:00,  4.71it/s]\n",
      "Sampling: 100%|██████████| 25/25 [00:05<00:00,  4.50it/s]\n",
      "Sampling: 100%|██████████| 25/25 [00:05<00:00,  4.59it/s]\n",
      "Sampling: 100%|██████████| 25/25 [00:05<00:00,  4.58it/s]\n",
      "Sampling: 100%|██████████| 25/25 [00:05<00:00,  4.39it/s]\n",
      "Sampling: 100%|██████████| 25/25 [00:05<00:00,  4.41it/s]\n",
      "Rendering: 300it [00:02, 125.60it/s]\n",
      "Rendering: 300it [00:02, 104.76it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "source_path = \"/store/real/ehliang/r2c2r_blender_data/r2c2r_data/test/StorageFurniture/44781/loop_0/link_3_rgb\"\n",
    "model_path = \"outputs/merged_example.glb\"\n",
    "pointcloud_path = \"/store/real/ehliang/r2c2r_blender_data/r2c2r_data/test/StorageFurniture/44781/loop_0/link_3.ply\"\n",
    "\n",
    "generate(source_path, model_path, pipeline, pointcloud_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.load(\"/store/real/ehliang/r2c2r_blender_data/r2c2r_data/test/StorageFurniture/44781/loop_0/link_3_occ_partial_64.pt\")\n",
    "\n",
    "model = model.unsqueeze(dim=0)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "r2c2r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
